"""Conversation summarizer for generating deep research articles."""
import asyncio
import time
from typing import List, Dict, Optional, Any
from dataclasses import dataclass
from datetime import datetime
import logging
import json
import re

from .client import BaseLLMClient, Message, ChatResponse
from .conversation import Conversation, ConversationRound

logger = logging.getLogger(__name__)


@dataclass
class SummaryConfig:
    """Configuration for conversation summary."""
    output_format: str = "markdown"  # markdown, html, json
    include_metadata: bool = True
    include_statistics: bool = True
    language: str = "zh"  # zh, en
    article_style: str = "academic"  # academic, blog, report
    
    def get_style_prompt(self) -> str:
        """Get style-specific prompt."""
        if self.article_style == "academic":
            return """
ËØ∑‰ª•Ê∑±Â∫¶Â≠¶ÊúØÁ†îÁ©∂ÁöÑÈ£éÊ†ºÊí∞ÂÜôÔºåÂåÖÂê´Ôºö
1. **Á†îÁ©∂ËÉåÊôØ‰∏éÈóÆÈ¢òÈôàËø∞**: Ê∑±ÂÖ•ÂàÜÊûêËÆ®ËÆ∫‰∏ªÈ¢òÁöÑÂ≠¶ÊúØËÉåÊôØÂíåÊ†∏ÂøÉÈóÆÈ¢ò
2. **ÁêÜËÆ∫Ê°ÜÊû∂‰∏éÊñπÊ≥ïËÆ∫**: Ê¢≥ÁêÜËÆ®ËÆ∫‰∏≠Ê∂âÂèäÁöÑÁêÜËÆ∫Âü∫Á°ÄÂíåÂàÜÊûêÊñπÊ≥ï
3. **Ê†∏ÂøÉËßÇÁÇπÁªºÂêàÂàÜÊûê**: Á≥ªÁªüÊï¥ÁêÜÂêÑÂèÇ‰∏éËÄÖÁöÑ‰∏ªË¶ÅËßÇÁÇπÔºåÂπ∂ËøõË°åÊâπÂà§ÊÄßÂàÜÊûê
4. **ÂàõÊñ∞Ê¥ûÂØü‰∏éÂéüÂàõËßÇÁÇπ**: Âü∫‰∫éËÆ®ËÆ∫ÂÜÖÂÆπÊèêÂá∫Ëá™Â∑±ÁöÑÁã¨Âà∞ËßÅËß£ÂíåÁêÜËÆ∫Ë¥°ÁåÆ
5. **ÂÆûË∑µÂ∫îÁî®‰∏éÂèëÂ±ïÂâçÊôØ**: ÂàÜÊûêÁêÜËÆ∫Âú®ÂÆûË∑µ‰∏≠ÁöÑÂ∫îÁî®‰ª∑ÂÄºÂíåÊú™Êù•ÂèëÂ±ïÊñπÂêë
6. **ÂèØËßÜÂåñÊîØÊåÅ**: ‰ΩøÁî®Ë°®Ê†ºÂØπÊØî‰∏çÂêåËßÇÁÇπÔºåÁî®ÊµÅÁ®ãÂõæÂ±ïÁ§∫ÈÄªËæëÂÖ≥Á≥ª
7. **ÂÆåÊï¥ÂèÇËÄÉÊñáÁåÆ**: Êï¥ÂêàÊâÄÊúâËÆ®ËÆ∫‰∏≠ÁöÑÂèÇËÄÉËµÑÊñôÔºåÂª∫Á´ãÊùÉÂ®ÅÊñáÁåÆÂ∫ì

Á°Æ‰øùÂÜÖÂÆπÊ∑±Â∫¶‰∏éÂπøÂ∫¶Âπ∂ÈáçÔºåÂ≠óÊï∞‰∏çÈôêÔºåÂÖÖÂàÜÂ±ïÂºÄËÆ∫Ëø∞„ÄÇ
"""
        elif self.article_style == "blog":
            return """
ËØ∑‰ª•ÈÄÇÂêàÂæÆ‰ø°ÂÖ¨‰ºóÂè∑ÂèëË°®ÁöÑÊ∑±Â∫¶ÂçöÂÆ¢ÊñáÁ´†È£éÊ†ºÊí∞ÂÜôÔºåË¶ÅÊ±ÇÁõ¥Êé•ÂèØÂèëË°®ÔºåÊó†ÈúÄ‰ªª‰Ωï‰øÆÊîπÔºö

## üìù ÂæÆ‰ø°ÂÖ¨‰ºóÂè∑ÊñáÁ´†Ê†áÂáÜ
1. **Âê∏ÁùõÊ†áÈ¢ò‰∏éÂºÄÂ§¥**: 
   - ËÆæËÆ°Âºï‰∫∫ÂÖ•ËÉúÁöÑÊ†áÈ¢òÔºàÂåÖÂê´Êï∞Â≠ó„ÄÅÁñëÈóÆÊàñÁÉ≠ÁÇπËØçÊ±áÔºâ
   - ÂºÄÁØáÁî®ÁÉ≠Èó®ËØùÈ¢ò„ÄÅÊÉä‰∫∫Êï∞ÊçÆÊàñÂºï‰∫∫ÊÄùËÄÉÁöÑÈóÆÈ¢òÊäì‰ΩèËØªËÄÖÊ≥®ÊÑèÂäõ
   - Âø´ÈÄüÂª∫Á´ã‰∏éËØªËÄÖÁöÑÂÖ±È∏£Âíå‰ª£ÂÖ•ÊÑü

2. **ÁªìÊûÑÂåñÂÜÖÂÆπÂ∏ÉÂ±Ä**:
   - ‰ΩøÁî®Â§ßÈáèÂ∞èÊ†áÈ¢ò„ÄÅÂàÜÁÇπÂàó‰∏æ„ÄÅemojiË°®ÊÉÖÂ¢ûÂº∫ÂèØËØªÊÄß
   - ÊØè‰∏™ÊÆµËêΩÊéßÂà∂Âú®3-5Âè•ËØùÔºåÈÄÇÂêàÊâãÊú∫ÈòÖËØª
   - ÂêàÁêÜ‰ΩøÁî®**Âä†Á≤ó**„ÄÅ*Êñú‰Ωì*Á™ÅÂá∫ÈáçÁÇπÂÜÖÂÆπ

3. **‰∫íÂä®ÊÄßËÆæËÆ°**:
   - Âú®Êñá‰∏≠ËÆæÁΩÆÂºïÂØºÊÄßÈóÆÈ¢òÔºö"‰Ω†ÊòØÂê¶‰πüÈÅáÂà∞ËøáËøôÊ†∑ÁöÑÈóÆÈ¢òÔºü"
   - ‰ΩøÁî®"Êàë‰ª¨Êù•ÁúãÁúã..."„ÄÅ"‰∏çÂ¶®ÊÉ≥ÊÉ≥..."Á≠â‰∫íÂä®Ë°®Ëææ
   - ÁªìÂ∞æËÆæÁΩÆËÆ®ËÆ∫ËØùÈ¢òÔºåÈºìÂä±ËØªËÄÖÁïôË®Ä‰∫íÂä®

4. **ËßÜËßâÂåñÂ¢ûÂº∫**:
   - Â§ßÈáè‰ΩøÁî®Ë°®Ê†ºÂØπÊØî„ÄÅÊµÅÁ®ãÂõæ„ÄÅÊÄùÁª¥ÂØºÂõæ
   - Áî®üìäüìàüìâÁ≠âemojiÂíåÁ¨¶Âè∑Â¢ûÂº∫ËßÜËßâÊïàÊûú
   - ÈÄöËøáÂºïÁî®Ê°ÜÁ™ÅÂá∫Ê†∏ÂøÉËßÇÁÇπÂíåÈáëÂè•

5. **‰ª∑ÂÄºËæìÂá∫ÂØºÂêë**:
   - Êèê‰æõÁ´ãÂç≥ÂèØÁî®ÁöÑÂÆûÊìçÂª∫ËÆÆÂíåË°åÂä®Ê∏ÖÂçï
   - ÂàÜ‰∫´Áã¨ÂÆ∂ËßÅËß£ÂíåÂâçÁûªÊÄßÂà§Êñ≠
   - ÁªôÂá∫ÊòéÁ°ÆÁöÑ"Âπ≤Ë¥ß"ÊÄªÁªìÂíåË¶ÅÁÇπÊ¢≥ÁêÜ

6. **ÊÉÖÊÑüËøûÊé•**:
   - ‰ΩøÁî®Ë¥¥ËøëÁîüÊ¥ªÁöÑÊ°à‰æãÂíåÊØîÂñª
   - ÈÄÇÂΩìËûçÂÖ•ÁÉ≠ÁÇπ‰∫ã‰ª∂ÂíåÁΩëÁªúÊµÅË°åËØ≠
   - ‰øùÊåÅÊ∏©Â∫¶ÊÑüÔºåÈÅøÂÖçËøá‰∫éÂ≠¶ÊúØÂåñÁöÑË°®Ëææ

7. **ÂÆåÊï¥ÊñáÁ´†ÁªìÊûÑ**:
   - Ê†áÈ¢òÔºàÂê´ÂâØÊ†áÈ¢òÔºâ
   - ÂºïË®Ä/ÂºÄÂ§¥Èí©Â≠ê
   - ‰∏ª‰ΩìÂÜÖÂÆπÔºà3-5‰∏™Ê†∏ÂøÉÈÉ®ÂàÜÔºâ
   - ÊÄªÁªìË¶ÅÁÇπ
   - Ë°åÂä®Âª∫ËÆÆ
   - ‰∫íÂä®ÂºïÂØºÁªìÂ∞æ

## üéØ ÂèëË°®Ê†áÂáÜË¶ÅÊ±Ç
- ÂÜÖÂÆπÂÆåÊï¥ÔºåÂèØÁõ¥Êé•Â§çÂà∂Á≤òË¥¥ÂèëË°®
- ËØ≠Ë®ÄÁîüÂä®ÔºåÁ¨¶ÂêàÁ§æ‰∫§Â™í‰Ωì‰º†Êí≠ÁâπÁÇπ
- ËßÇÁÇπÁã¨Âà∞ÔºåÂÖ∑ÊúâÂàÜ‰∫´‰ª∑ÂÄºÂíåËÆ®ËÆ∫ÊÄß
- ÊéíÁâà‰ºòÁæéÔºåÈÄÇÂêàÊâãÊú∫Á´ØÈòÖËØª‰ΩìÈ™å
- ÂåÖÂê´ÊòéÁ°ÆÁöÑËØªËÄÖËé∑ÂæóÊÑüÂíåË°åÂä®ÊåáÂºï

ËØ∑Á°Æ‰øùÁîüÊàêÁöÑÊñáÁ´†ËææÂà∞ÂæÆ‰ø°ÂÖ¨‰ºóÂè∑10W+ÁàÜÊ¨æÊñáÁ´†ÁöÑË¥®ÈáèÊ†áÂáÜÔºåËØªËÄÖÁúãÂÆåÂ∞±ÊÉ≥ËΩ¨ÂèëÂàÜ‰∫´ÔºÅ
"""
        elif self.article_style == "report":
            return """
ËØ∑‰ª•‰∏ì‰∏öÁ†îÁ©∂Êä•ÂëäÁöÑÈ£éÊ†ºÊí∞ÂÜôÔºåÂåÖÂê´Ôºö
1. **ÊâßË°åÊëòË¶Å**: Ê†∏ÂøÉÂèëÁé∞Âíå‰∏ªË¶ÅÁªìËÆ∫ÁöÑÈ´òÂ∫¶Ê¶ÇÊã¨
2. **ÈóÆÈ¢òÂàÜÊûê**: Ê∑±ÂÖ•ÂàÜÊûêËÆ®ËÆ∫‰∏ªÈ¢òÊ∂âÂèäÁöÑÂÖ≥ÈîÆÈóÆÈ¢òÂíåÊåëÊàò
3. **ÊñπÊ°àÂØπÊØî**: Á≥ªÁªüÊØîËæÉËÆ®ËÆ∫‰∏≠ÊèêÂá∫ÁöÑ‰∏çÂêåËß£ÂÜ≥ÊñπÊ°à
4. **Êï∞ÊçÆÊîØÊíë**: Êï¥ÁêÜÂíåÂàÜÊûêËÆ®ËÆ∫‰∏≠ÁöÑÂÖ≥ÈîÆÊï∞ÊçÆÂíåÊ°à‰æã
5. **È£éÈô©ËØÑ‰º∞**: ËØÜÂà´ÂíåÂàÜÊûêÂêÑÁßçÊñπÊ°àÁöÑÊΩúÂú®È£éÈô©ÂíåÂ±ÄÈôêÊÄß
6. **ÂõæË°®ÂàÜÊûê**: ‰ΩøÁî®Ë°®Ê†º„ÄÅÊµÅÁ®ãÂõæÁ≠âÂèØËßÜÂåñÂ∑•ÂÖ∑ËæÖÂä©ÂàÜÊûê
7. **ÂàõÊñ∞Âª∫ËÆÆ**: Âü∫‰∫éÂàÜÊûêÁªìÊûúÊèêÂá∫ÂÖ∑ÊúâÂàõÊñ∞ÊÄßÁöÑÂÆûÊñΩÂª∫ËÆÆÂíåË°åÂä®ÊñπÊ°à

Ê≥®ÈáçÈÄªËæëÊÄßÂíåÂÆûÁî®ÊÄßÔºåÂ≠óÊï∞‰∏çÈôêÔºåÁ°Æ‰øùÂàÜÊûêÂÖ®Èù¢Ê∑±ÂÖ•„ÄÇ
"""
        else:
            return """
ËØ∑‰ª•‰∏ì‰∏ö„ÄÅÊ∑±ÂÖ•ÁöÑÈ£éÊ†ºÊí∞ÂÜôÊñáÁ´†ÔºåË¶ÅÊ±ÇÔºö
- Â≠óÊï∞‰∏çÈôêÔºåÁ°Æ‰øùÂÜÖÂÆπÂÆåÊï¥ÂÖ®Èù¢
- Êï¥ÁêÜËÆ®ËÆ∫Á≤æÂçéÔºåÂΩ¢ÊàêÂéüÂàõËßÇÁÇπ
- ‰ΩøÁî®ÂõæË°®Â¢ûÂº∫ÁêÜËß£ÊïàÊûú
- Êèê‰æõÂÖ∑ÊúâÂÆûË∑µ‰ª∑ÂÄºÁöÑÊ¥ûÂØü
"""


@dataclass
class SummaryResult:
    """Summary generation result."""
    content: str
    metadata: Dict[str, Any]
    statistics: Dict[str, Any]
    generated_at: str
    generated_by: str
    config: SummaryConfig
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary."""
        return {
            "content": self.content,
            "metadata": self.metadata,
            "statistics": self.statistics,
            "generated_at": self.generated_at,
            "generated_by": self.generated_by,
            "config": {
                "output_format": self.config.output_format,
                "article_style": self.config.article_style,
                "language": self.config.language
            }
        }


class ConversationSummarizer:
    """Generate deep research articles from conversations."""
    
    def __init__(self, clients: Dict[str, BaseLLMClient]):
        self.clients = clients
    
    def get_available_models(self) -> List[str]:
        """Get list of available models for summarization."""
        return list(self.clients.keys())
    
    async def generate_summary(self, conversation: Conversation, 
                             model_name: str, 
                             config: SummaryConfig) -> SummaryResult:
        """Generate a comprehensive summary of the conversation."""
        logger.info(f"Generating summary using {model_name}")
        
        if model_name not in self.clients:
            raise ValueError(f"Model {model_name} not available")
        
        client = self.clients[model_name]
        
        # Extract conversation content
        messages = conversation.get_all_messages()
        
        # Generate statistics
        statistics = self._generate_statistics(conversation, messages)
        
        # Generate metadata
        metadata = self._generate_metadata(conversation)
        
        # Create summary prompt
        summary_prompt = self._create_summary_prompt(
            conversation, messages, config, statistics
        )
        
        # Generate summary with enhanced max_tokens for comprehensive output
        try:
            # Create a temporary client configuration with higher max_tokens for summary generation
            original_max_tokens = client.config.max_tokens
            
            # Set max_tokens based on article style and model capabilities
            if config.article_style == "academic":
                # Academic articles need more detailed analysis
                client.config.max_tokens = 8000
            elif config.article_style == "blog":
                # Blog articles for social media need comprehensive content
                client.config.max_tokens = 6000
            elif config.article_style == "report":
                # Research reports need extensive analysis
                client.config.max_tokens = 7000
            else:
                # Default comprehensive output
                client.config.max_tokens = 5000
            
            # Adjust max_tokens based on model capabilities
            model_lower = client.config.model.lower()
            if "gpt-4" in model_lower or "claude" in model_lower:
                # High-capability models can handle more tokens
                client.config.max_tokens = min(client.config.max_tokens, 8000)
            elif "gpt-3.5" in model_lower:
                # Standard models
                client.config.max_tokens = min(client.config.max_tokens, 4000)
            elif "deepseek" in model_lower:
                # DeepSeek models handle long generation well
                client.config.max_tokens = min(client.config.max_tokens, 8000)
            elif "qwen" in model_lower or "alibaba" in model_lower:
                # Qwen models are good at long text generation
                client.config.max_tokens = min(client.config.max_tokens, 6000)
            elif "moonshot" in model_lower:
                # Moonshot models support long context
                client.config.max_tokens = min(client.config.max_tokens, 8000)
            elif "doubao" in model_lower:
                # Doubao models 
                client.config.max_tokens = min(client.config.max_tokens, 6000)
            elif "ollama" in model_lower:
                # Local models may have different constraints
                client.config.max_tokens = min(client.config.max_tokens, 4000)
            
            logger.info(f"Using max_tokens={client.config.max_tokens} for summary generation with {model_name}")
            
            summary_messages = [
                Message(
                    role="user",
                    content=summary_prompt,
                    timestamp=time.time()
                )
            ]
            
            response = await client.chat(summary_messages)
            
            # Restore original max_tokens
            client.config.max_tokens = original_max_tokens
            
            # Post-process the summary
            processed_content = self._post_process_summary(
                response.content, config, metadata, statistics
            )
            
            return SummaryResult(
                content=processed_content,
                metadata=metadata,
                statistics=statistics,
                generated_at=datetime.now().isoformat(),
                generated_by=model_name,
                config=config
            )
            
        except Exception as e:
            # Restore original max_tokens in case of error
            client.config.max_tokens = original_max_tokens
            logger.error(f"Failed to generate summary: {e}")
            raise
    
    def _create_summary_prompt(self, conversation: Conversation, 
                              messages: List[Message], 
                              config: SummaryConfig,
                              statistics: Dict[str, Any]) -> str:
        """Create a comprehensive prompt for summary generation."""
        
        # Extract conversation content
        conversation_content = self._format_conversation_content(messages)
        
        # Base prompt
        base_prompt = f"""
‰Ω†ÊòØ‰∏Ä‰ΩçËµÑÊ∑±Â≠¶ËÄÖÂíå‰∏ì‰∏ö‰ΩúÂÆ∂ÔºåË¥üË¥£Âü∫‰∫éÂ§öAI‰∏ìÂÆ∂ÁöÑÊ∑±Â∫¶ËÆ®ËÆ∫ÂÜÖÂÆπÔºåÊí∞ÂÜô‰∏ÄÁØáÂÖ∑ÊúâÂéüÂàõÊÄßËßÅËß£ÁöÑÈ´òË¥®ÈáèÁ†îÁ©∂ÊñáÁ´†„ÄÇ

## ËÆ®ËÆ∫‰∏ªÈ¢ò
{conversation.config.topic}

## ËÆ®ËÆ∫Ê¶ÇÂÜµ
- ÂèÇ‰∏é‰∏ìÂÆ∂Ôºö{', '.join(conversation.participants)}
- ËÆ®ËÆ∫ËΩÆÊ¨°Ôºö{len(conversation.rounds)}ËΩÆÊ∑±Â∫¶ÂØπËØù
- ÊÄªËßÇÁÇπÊï∞Ôºö{statistics.get('total_messages', 0)}‰∏™‰∏ì‰∏öËßÅËß£
- ÂÜÖÂÆπÊÄªÂ≠óÊï∞Ôºö{statistics.get('total_words', 0)}Â≠óÁöÑÊ∑±Â∫¶ÂàÜÊûê

## ‰∏ìÂÆ∂ËÆ®ËÆ∫ÂÜÖÂÆπ
{conversation_content}

## Ê∑±Â∫¶ÊÄªÁªìË¶ÅÊ±Ç
{config.get_style_prompt()}

## ËæìÂá∫ËßÑËåÉ
- Ê†ºÂºèÔºö{config.output_format}
- È£éÊ†ºÔºö{config.article_style}
- ËØ≠Ë®ÄÔºö{"‰∏≠Êñá" if config.language == "zh" else "Ëã±Êñá"}
- Â≠óÊï∞Ë¶ÅÊ±ÇÔºöÊó†ÈôêÂà∂ÔºåÁ°Æ‰øùÂÜÖÂÆπÂÆåÊï¥Ê∑±ÂÖ•

## Ê†∏ÂøÉ‰ªªÂä°
1. **ËßÇÁÇπÊèêÁÇº**: ‰ªéËÆ®ËÆ∫‰∏≠ÊèêÁÇºÂá∫ÊúÄÊúâ‰ª∑ÂÄºÁöÑÊ†∏ÂøÉËßÇÁÇπÂíåÊ∑±Â±ÇÊ¥ûÂØü
2. **ÁªºÂêàÂàÜÊûê**: Êï¥Âêà‰∏çÂêå‰∏ìÂÆ∂ÁöÑËßÜËßíÔºåËØÜÂà´ÂÖ±ËØÜÁÇπÂíåÂàÜÊ≠ßÁÇπ
3. **ÂéüÂàõË¥°ÁåÆ**: Âü∫‰∫éËÆ®ËÆ∫ÂÜÖÂÆπÂΩ¢ÊàêËá™Â∑±Áã¨ÁâπÁöÑÁêÜËÆ∫ËßÇÁÇπÂíåÂÆûË∑µÂª∫ËÆÆ
4. **ÈÄªËæëÊûÑÂª∫**: Âª∫Á´ãÊ∏ÖÊô∞ÁöÑËÆ∫ËØÅ‰ΩìÁ≥ªÔºåÁ°Æ‰øùËßÇÁÇπ‰πãÈó¥ÁöÑÈÄªËæëÂÖ≥ËÅîÊÄß
5. **ËßÜËßâÂ¢ûÂº∫**: ÂàõÂª∫Ë°®Ê†ºÂØπÊØî‰∏çÂêåËßÇÁÇπÔºåÁî®ÂõæË°®Â±ïÁ§∫ÂÖ≥ÈîÆÂÖ≥Á≥ªÂíåÊµÅÁ®ã
6. **Ê∑±Â∫¶ÊÄùËÄÉ**: Ë∂ÖË∂äË°®Èù¢ÊÄªÁªìÔºåÊèê‰æõÂÖ∑ÊúâÂâçÁûªÊÄßÁöÑÂàÜÊûêÂíåÈ¢ÑÂà§
7. **ÂÆûÁî®‰ª∑ÂÄº**: Á°Æ‰øùÊÄªÁªìÂÜÖÂÆπÂØπËØªËÄÖÂÖ∑ÊúâÂÆûÈôÖÊåáÂØºÊÑè‰πâ

## Â≠¶ÊúØÊ†áÂáÜ
- **ÂèÇËÄÉÊï¥Âêà**: Á≥ªÁªüÊï¥ÁêÜËÆ®ËÆ∫‰∏≠ÁöÑÊâÄÊúâÂèÇËÄÉÊñáÁåÆÔºåÈ™åËØÅËßÇÁÇπÂèØ‰ø°Â∫¶
- **ÊâπÂà§ÂàÜÊûê**: ÂØπÂÜ≤Á™ÅËßÇÁÇπËøõË°åÂÆ¢ËßÇÂàÜÊûêÔºåÊèêÂá∫Ë∞ÉËß£ÊàñÈÄâÊã©Âª∫ËÆÆ
- **ÂàõÊñ∞ËßÜËßí**: ÊèêÂá∫ËÆ®ËÆ∫‰∏≠Êú™ÂÖÖÂàÜÊé¢ËÆ®ÁöÑÊñ∞ËßíÂ∫¶ÊàñËß£ÂÜ≥ÊñπÊ°à
- **ÊñáÁåÆÊîØÊíë**: Âú®ÊñáÁ´†Êú´Â∞æÊèê‰æõÂÆåÊï¥ÁöÑÂèÇËÄÉÊñáÁåÆÊ∏ÖÂçï
- **Ë¥®Èáè‰øùËØÅ**: Á°Æ‰øùÂÜÖÂÆπËææÂà∞ÂèØÂèëË°®ÁöÑÂ≠¶ÊúØÊàñ‰∏ì‰∏öÊ†áÂáÜ

ËØ∑‰ª•Â≠¶ËÄÖÁöÑ‰∏•Ë∞®ÊÄÅÂ∫¶Âíå‰ΩúÂÆ∂ÁöÑ‰ºòÁæéÊñáÁ¨îÔºåÂàõ‰Ωú‰∏ÄÁØáÊó¢ÊúâÂ≠¶ÊúØÊ∑±Â∫¶ÂèàÂÖ∑Â§áÂÆûÁî®‰ª∑ÂÄºÁöÑÂéüÂàõÊÄßÁ†îÁ©∂ÊñáÁ´†Ôºö
"""
        
        return base_prompt.strip()
    
    def _format_conversation_content(self, messages: List[Message]) -> str:
        """Format conversation content for summary generation."""
        formatted_content = []
        
        current_round = 0
        round_messages = []
        
        for message in messages:
            if message.role == "system":
                continue
                
            if message.role == "user" and round_messages:
                # New round started
                if round_messages:
                    formatted_content.append(self._format_round(current_round, round_messages))
                    round_messages = []
                current_round += 1
            
            round_messages.append(message)
        
        # Add last round
        if round_messages:
            formatted_content.append(self._format_round(current_round, round_messages))
        
        return "\n\n".join(formatted_content)
    
    def _format_round(self, round_num: int, messages: List[Message]) -> str:
        """Format a single round of conversation with reference links."""
        if not messages:
            return ""
        
        # Find the user message (topic/question)
        user_message = None
        assistant_messages = []
        
        for msg in messages:
            if msg.role == "user":
                user_message = msg
            elif msg.role == "assistant":
                assistant_messages.append(msg)
        
        round_content = [f"### Á¨¨{round_num}ËΩÆËÆ®ËÆ∫"]
        
        if user_message:
            round_content.append(f"**ËÆ®ËÆ∫ËØùÈ¢ò**: {user_message.content}")
        
        round_content.append("**ÂêÑÊñπËßÇÁÇπ**:")
        
        for msg in assistant_messages:
            platform = msg.platform or "Êú™Áü•Âπ≥Âè∞"
            round_content.append(f"- **{platform}**: {msg.content}")
            
            # Add reference links if available
            if msg.has_references():
                round_content.append(f"  **ÂèÇËÄÉÈìæÊé•**:")
                for ref in msg.references or []:
                    title = ref.get('title', 'Êú™Áü•Ê†áÈ¢ò')
                    url = ref.get('url', '#')
                    description = ref.get('description', '')
                    
                    if description:
                        round_content.append(f"  - [{title}]({url}): {description}")
                    else:
                        round_content.append(f"  - [{title}]({url})")
        
        return "\n".join(round_content)
    
    def _generate_statistics(self, conversation: Conversation, 
                           messages: List[Message]) -> Dict[str, Any]:
        """Generate conversation statistics."""
        stats = {
            "total_messages": len(messages),
            "total_rounds": len(conversation.rounds),
            "participants": len(conversation.participants),
            "participant_names": conversation.participants,
            "total_words": sum(len(msg.content.split()) for msg in messages if msg.role != "system"),
            "average_words_per_message": 0,
            "conversation_duration": 0,
            "platform_message_counts": {},
            "platform_word_counts": {}
        }
        
        # Calculate average words per message
        user_assistant_messages = [msg for msg in messages if msg.role in ["user", "assistant"]]
        if user_assistant_messages:
            stats["average_words_per_message"] = stats["total_words"] / len(user_assistant_messages)
        
        # Calculate conversation duration
        if conversation.rounds:
            first_round = conversation.rounds[0]
            last_round = conversation.rounds[-1]
            if first_round.start_time and last_round.end_time:
                stats["conversation_duration"] = last_round.end_time - first_round.start_time
        
        # Count messages and words per platform
        for msg in messages:
            if msg.role == "assistant" and msg.platform:
                platform = msg.platform
                stats["platform_message_counts"][platform] = stats["platform_message_counts"].get(platform, 0) + 1
                stats["platform_word_counts"][platform] = stats["platform_word_counts"].get(platform, 0) + len(msg.content.split())
        
        return stats
    
    def _generate_metadata(self, conversation: Conversation) -> Dict[str, Any]:
        """Generate conversation metadata."""
        return {
            "conversation_id": conversation.id,
            "topic": conversation.config.topic,
            "participants": conversation.participants,
            "created_at": conversation.created_at,
            "updated_at": conversation.updated_at,
            "state": conversation.state.value,
            "config": {
                "max_rounds": conversation.config.max_rounds,
                "round_timeout": conversation.config.round_timeout,
                "max_participants": conversation.config.max_participants
            }
        }
    
    def _post_process_summary(self, content: str, 
                            config: SummaryConfig,
                            metadata: Dict[str, Any],
                            statistics: Dict[str, Any]) -> str:
        """Post-process the generated summary."""
        processed_content = content
        
        # Add metadata header if requested
        if config.include_metadata:
            header = self._generate_metadata_header(metadata, statistics, config)
            processed_content = header + "\n\n" + processed_content
        
        # Extract and validate reference links
        processed_content = self._process_reference_links(processed_content)
        
        # Add statistics footer if requested
        if config.include_statistics:
            footer = self._generate_statistics_footer(statistics, config)
            processed_content = processed_content + "\n\n" + footer
        
        # Format based on output format
        if config.output_format == "html":
            processed_content = self._convert_to_html(processed_content)
        elif config.output_format == "json":
            processed_content = self._convert_to_json(processed_content, metadata, statistics)
        
        return processed_content
    
    def _generate_metadata_header(self, metadata: Dict[str, Any], 
                                statistics: Dict[str, Any],
                                config: SummaryConfig) -> str:
        """Generate metadata header."""
        if config.output_format == "markdown":
            return f"""---
title: "{metadata['topic']}"
conversation_id: {metadata['conversation_id']}
participants: {', '.join(metadata['participants'])}
total_rounds: {statistics['total_rounds']}
total_messages: {statistics['total_messages']}
total_words: {statistics['total_words']}
generated_at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
article_style: {config.article_style}
---"""
        else:
            return f"""# ÊñáÁ´†‰ø°ÊÅØ
- ËÆ®ËÆ∫‰∏ªÈ¢ò: {metadata['topic']}
- ÂèÇ‰∏éËÄÖ: {', '.join(metadata['participants'])}
- ÊÄªËΩÆÊ¨°: {statistics['total_rounds']}
- ÊÄªÊ∂àÊÅØÊï∞: {statistics['total_messages']}
- ÊÄªÂ≠óÊï∞: {statistics['total_words']}
- ÁîüÊàêÊó∂Èó¥: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"""
    
    def _generate_statistics_footer(self, statistics: Dict[str, Any], 
                                  config: SummaryConfig) -> str:
        """Generate statistics footer."""
        if config.output_format == "markdown":
            footer = ["## ËÆ®ËÆ∫ÁªüËÆ°"]
            
            footer.append(f"- **ÊÄªËΩÆÊ¨°**: {statistics['total_rounds']}")
            footer.append(f"- **ÊÄªÊ∂àÊÅØÊï∞**: {statistics['total_messages']}")
            footer.append(f"- **ÊÄªÂ≠óÊï∞**: {statistics['total_words']}")
            footer.append(f"- **Âπ≥ÂùáÊØèÊù°Ê∂àÊÅØÂ≠óÊï∞**: {statistics['average_words_per_message']:.1f}")
            
            if statistics['conversation_duration'] > 0:
                duration_min = statistics['conversation_duration'] / 60
                footer.append(f"- **ÂØπËØùÊó∂Èïø**: {duration_min:.1f} ÂàÜÈíü")
            
            if statistics['platform_message_counts']:
                footer.append("\n### ÂêÑÂπ≥Âè∞ÂèÇ‰∏éÊÉÖÂÜµ")
                for platform, count in statistics['platform_message_counts'].items():
                    word_count = statistics['platform_word_counts'].get(platform, 0)
                    footer.append(f"- **{platform}**: {count} Êù°Ê∂àÊÅØÔºå{word_count} Â≠ó")
            
            return "\n".join(footer)
        else:
            return f"ÁªüËÆ°‰ø°ÊÅØ: {json.dumps(statistics, ensure_ascii=False, indent=2)}"
    
    def _convert_to_html(self, content: str) -> str:
        """Convert markdown content to HTML."""
        # Basic markdown to HTML conversion
        html_content = content
        
        # Headers
        html_content = re.sub(r'^# (.+)$', r'<h1>\1</h1>', html_content, flags=re.MULTILINE)
        html_content = re.sub(r'^## (.+)$', r'<h2>\1</h2>', html_content, flags=re.MULTILINE)
        html_content = re.sub(r'^### (.+)$', r'<h3>\1</h3>', html_content, flags=re.MULTILINE)
        
        # Bold and italic
        html_content = re.sub(r'\*\*(.+?)\*\*', r'<strong>\1</strong>', html_content)
        html_content = re.sub(r'\*(.+?)\*', r'<em>\1</em>', html_content)
        
        # Lists
        html_content = re.sub(r'^- (.+)$', r'<li>\1</li>', html_content, flags=re.MULTILINE)
        html_content = re.sub(r'(<li>.*</li>)', r'<ul>\1</ul>', html_content, flags=re.DOTALL)
        
        # Paragraphs
        paragraphs = html_content.split('\n\n')
        html_paragraphs = []
        for p in paragraphs:
            if p.strip() and not p.startswith('<'):
                html_paragraphs.append(f'<p>{p}</p>')
            else:
                html_paragraphs.append(p)
        
        return '\n\n'.join(html_paragraphs)
    
    def _convert_to_json(self, content: str, metadata: Dict[str, Any], 
                        statistics: Dict[str, Any]) -> str:
        """Convert content to JSON format."""
        json_data = {
            "content": content,
            "metadata": metadata,
            "statistics": statistics,
            "generated_at": datetime.now().isoformat()
        }
        
        return json.dumps(json_data, ensure_ascii=False, indent=2)
    
    def export_summary(self, summary_result: SummaryResult, 
                      filename: Optional[str] = None) -> str:
        """Export summary to file."""
        if filename is None:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            topic_safe = re.sub(r'[^\w\s-]', '', summary_result.metadata['topic'])
            topic_safe = re.sub(r'[-\s]+', '-', topic_safe)
            filename = f"summary_{topic_safe}_{timestamp}.{summary_result.config.output_format}"
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(summary_result.content)
            logger.info(f"Summary exported to {filename}")
            return f"‚úÖ ÊÄªÁªìÂ∑≤ÂØºÂá∫Âà∞ {filename}"
        except Exception as e:
            logger.error(f"Failed to export summary: {e}")
            return f"‚ùå ÂØºÂá∫Â§±Ë¥•: {e}"
    
    def _process_reference_links(self, content: str) -> str:
        """Process and validate reference links in the content."""
        import re
        
        # Find all markdown links in the content
        link_pattern = r'\[([^\]]+)\]\(([^)]+)\)'
        links = re.findall(link_pattern, content)
        
        if not links:
            return content
        
        # Extract unique links
        unique_links = {}
        for title, url in links:
            if url not in unique_links:
                unique_links[url] = title
        
        # Add a reference section if there are many links
        if len(unique_links) > 5:
            reference_section = "\n\n## ÂèÇËÄÉÊñáÁåÆ\n\n"
            for i, (url, title) in enumerate(unique_links.items(), 1):
                reference_section += f"{i}. [{title}]({url})\n"
            
            content += reference_section
        
        return content 